{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_laptime_1120.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wVRRuzSBICgr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import modules"
      ]
    },
    {
      "metadata": {
        "id": "g6CgbhUrvbG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qvk8W8HhIIF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "데이터 불러오기, 결측치 제거, 변수 선택"
      ]
    },
    {
      "metadata": {
        "id": "VU4jJHIlvphP",
        "colab_type": "code",
        "outputId": "f09ffaca-a825-4163-b675-a4b0c175f541",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "data = pd.read_csv(\"clogit_df.csv\",encoding='utf-8')\n",
        "print(\"전체 데이터 개수 : \",len(data))\n",
        "\n",
        "\n",
        "# 2016년 이후 데이터\n",
        "data = data[0:27939]\n",
        "\n",
        "\n",
        "# 결측치 제거 (X,y 변수 모두!)\n",
        "data = data.dropna(subset=['distance','record',\n",
        "                           'date','code','lane','age','jockey_w','dandivi','yeondivi',\n",
        "                           'cure_in_1m','weight_diff', 'raw_weight','weight_added','jockey',\n",
        "                           'prev1_velo','prev2_velo','sex1','sex2'])\n",
        "\n",
        "print(\"결측치 제거 후 개수 : \",len(data))\n",
        "\n",
        "\n",
        "# distance별로 데이터 나누기\n",
        "\n",
        "gb_distance = data.groupby(['distance'])\n",
        "gb_distance=[gb_distance.get_group(x) for x in gb_distance.groups]\n",
        "\n",
        "# distance list\n",
        "distance_list = list(set(data['distance']))\n",
        "distance_list.sort()\n",
        "\n",
        "for i in range(len(gb_distance)):\n",
        "  print(distance_list[i] ,\"m 거리에서 데이터 개수 : \",len(gb_distance[i]))\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 개수 :  56576\n",
            "결측치 제거 후 개수 :  27922\n",
            "1000.0 m 거리에서 데이터 개수 :  4228\n",
            "1200.0 m 거리에서 데이터 개수 :  6410\n",
            "1300.0 m 거리에서 데이터 개수 :  7621\n",
            "1400.0 m 거리에서 데이터 개수 :  3379\n",
            "1700.0 m 거리에서 데이터 개수 :  3890\n",
            "1800.0 m 거리에서 데이터 개수 :  1685\n",
            "1900.0 m 거리에서 데이터 개수 :  295\n",
            "2000.0 m 거리에서 데이터 개수 :  377\n",
            "2300.0 m 거리에서 데이터 개수 :  37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qJUB8LMU1rFq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 데이터 가장 많은 Dataframe 선택  \n",
        "data=gb_distance[2]\n",
        "\n",
        "\n",
        "# X,y 데이터 나누기 (변수 결정하기)\n",
        "y = data['record']\n",
        "X = data.loc[:, ['date','code','lane','age','jockey_w','dandivi','yeondivi',\n",
        "                 'cure_in_1m','weight_diff', 'raw_weight','weight_added','jockey',\n",
        "                 'prev1_velo','prev2_velo','sex1','sex2']]\n",
        "\n",
        "\n",
        "# X에 year,month 추가\n",
        "year=[]\n",
        "month=[]\n",
        "\n",
        "# print(X.shape)\n",
        "for i in range(X.shape[0]):\n",
        "  word =list(X['date'])[i].split(\"-\")\n",
        "  year.append(int(word[0])-2010)\n",
        "  month.append(int(word[1]))\n",
        "  \n",
        "X['year'] = year\n",
        "X['month'] = month\n",
        "#print(X['year'],X['month'])\n",
        "X=X.drop(['date'],axis=1)\n",
        "\n",
        "\n",
        "# \n",
        "X = X.as_matrix()\n",
        "y = y.as_matrix()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ui5OcTvJ1RlM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 설정하는 부분\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 400\n",
        "batch_size = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "akNj9hoTw707",
        "colab_type": "code",
        "outputId": "10fedb3c-28ea-4a80-d0db-eec33d500ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Train , Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "train_size = len(X_train)\n",
        "print(\"train_size : \",train_size)\n",
        "\n",
        "size_x = len(X_train[0])\n",
        "print(\"size_x : \",size_x)\n"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_size :  5334\n",
            "size_x :  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp1UPD0YQA2i",
        "colab_type": "code",
        "outputId": "887af254-dc73-4582-b933-34ab5b258932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "cell_type": "code",
      "source": [
        "# Normalize \n",
        "\n",
        "X_mean = []\n",
        "X_std = []\n",
        "\n",
        "for i in range(size_x):\n",
        "  X_mean.append(np.mean(X_train[:,i]))\n",
        "  X_std.append(np.std(X_train[:,i]))\n",
        "  print(i+1,\"번째 변수의 X_mean:\",'{:.3f}'.format(X_mean[i]),\", X_std:\",'{:.3f}'.format(X_std[i]))\n",
        "  X_train[:,i] = (X_train[:,i]-X_mean[i])/X_std[i]\n",
        "  X_test[:,i] = (X_test[:,i]-X_mean[i])/X_std[i]\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 번째 변수의 X_mean: 34655.511 , X_std: 2175.502\n",
            "2 번째 변수의 X_mean: 6.037 , X_std: 3.298\n",
            "3 번째 변수의 X_mean: 3.559 , X_std: 0.832\n",
            "4 번째 변수의 X_mean: 53.813 , X_std: 1.697\n",
            "5 번째 변수의 X_mean: 32.363 , X_std: 40.711\n",
            "6 번째 변수의 X_mean: 5.886 , X_std: 6.523\n",
            "7 번째 변수의 X_mean: 0.276 , X_std: 0.447\n",
            "8 번째 변수의 X_mean: 0.218 , X_std: 6.963\n",
            "9 번째 변수의 X_mean: 468.546 , X_std: 27.147\n",
            "10 번째 변수의 X_mean: 0.218 , X_std: 6.963\n",
            "11 번째 변수의 X_mean: 80452.806 , X_std: 118.615\n",
            "12 번째 변수의 X_mean: 15.572 , X_std: 0.387\n",
            "13 번째 변수의 X_mean: 15.575 , X_std: 0.389\n",
            "14 번째 변수의 X_mean: 0.318 , X_std: 0.466\n",
            "15 번째 변수의 X_mean: 0.465 , X_std: 0.499\n",
            "16 번째 변수의 X_mean: 6.915 , X_std: 0.790\n",
            "17 번째 변수의 X_mean: 6.053 , X_std: 3.292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bpRzgT_sQBpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, size_x])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "phase = tf.placeholder(tf.bool, name='phase')\n",
        "\n",
        "# First Layer\n",
        "\n",
        "W1 = tf.get_variable(shape=[size_x, 128], name='weight1', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([128]))\n",
        "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
        "layer1 = tf.nn.dropout(layer1, keep_prob=keep_prob)\n",
        "layer1 = tf.contrib.layers.batch_norm(layer1, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "\n",
        "# Second Layer\n",
        "\n",
        "W2 = tf.get_variable(shape=[128, 64], name='weight2', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([64]))\n",
        "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
        "layer2 = tf.nn.dropout(layer2, keep_prob=keep_prob)\n",
        "layer2 = tf.contrib.layers.batch_norm(layer2, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "# Third Layer\n",
        "\n",
        "W3 = tf.get_variable(shape=[64, 32], name='weight3', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([32]))\n",
        "layer3 = tf.nn.relu(tf.matmul(layer2, W3) + b3)\n",
        "layer3 = tf.nn.dropout(layer3, keep_prob=keep_prob)\n",
        "layer3 = tf.contrib.layers.batch_norm(layer3, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "# Predict\n",
        "\n",
        "W4 = tf.get_variable(shape=[32, 1], name='weight4', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([1]))\n",
        "hypothesis = tf.matmul(layer3, W4) + b4\n",
        "hypothesis = tf.contrib.layers.batch_norm(hypothesis, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vw9hOOSIQB9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cost 계산\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgwudOfwQBxq",
        "colab_type": "code",
        "outputId": "5abfcaf6-3644-400b-eff9-25555244bf17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "# 계산 시작\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "prev_avg_cost = 0\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(train_size / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        # batch_size로 X,y 개수 나눠주기\n",
        "        batch_xs = X_train[i*batch_size:(i+1)*batch_size]\n",
        "        batch_ys = y_train[i*batch_size:(i+1)*batch_size].reshape(batch_size,1)\n",
        "        \n",
        "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob:0.7,phase:True}\n",
        "        c, _ = sess.run([cost, train], feed_dict=feed_dict)\n",
        "        avg_cost += c/total_batch\n",
        "        \n",
        "    # 20 epoch마다 cost\n",
        "    \n",
        "    if (epoch+1) % 20==0:\n",
        "      print('Epoch:', '%04d' % (epoch+1), 'cost =', '{:.5f}'.format(avg_cost))\n",
        "      \n",
        "    if abs(prev_avg_cost - avg_cost) <= 0.005:\n",
        "      break\n",
        "    prev_avg_cost = avg_cost\n",
        "    \n",
        "print('Epoch:', '%04d' % (epoch + 1), ' cost =', '{:.9f}'.format(avg_cost))\n"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0020 cost = 5728.64654\n",
            "Epoch: 0040 cost = 4621.44018\n",
            "Epoch: 0060 cost = 3664.69507\n",
            "Epoch: 0080 cost = 2842.20485\n",
            "Epoch: 0100 cost = 2142.69584\n",
            "Epoch: 0120 cost = 1557.79973\n",
            "Epoch: 0140 cost = 1080.61521\n",
            "Epoch: 0160 cost = 704.57992\n",
            "Epoch: 0180 cost = 422.40740\n",
            "Epoch: 0200 cost = 225.37727\n",
            "Epoch: 0220 cost = 101.51798\n",
            "Epoch: 0240 cost = 35.77377\n",
            "Epoch: 0260 cost = 9.18471\n",
            "Epoch: 0280 cost = 2.34573\n",
            "Epoch: 0300 cost = 1.60932\n",
            "Epoch: 0303  cost = 1.628491535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PnTPAT_Ez9La",
        "colab_type": "code",
        "outputId": "329529e8-a40f-49c2-f976-d688ee418fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Test set 계산\n",
        "\n",
        "y_test = y_test.reshape(-1,1)\n",
        "mse = tf.reduce_mean(tf.square(hypothesis - Y))**0.5\n",
        "print('Cost of test set:', sess.run(mse, feed_dict={\n",
        "      X: X_test, Y: y_test, keep_prob:1, phase:False}))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost of test set: 1640.1909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eYBCKhgi4TUy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}