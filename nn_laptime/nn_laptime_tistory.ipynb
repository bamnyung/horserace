{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_laptime_1120.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "wVRRuzSBICgr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Import modules"
      ]
    },
    {
      "metadata": {
        "id": "g6CgbhUrvbG5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qvk8W8HhIIF-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "데이터 불러오기, 결측치 제거, 변수 선택"
      ]
    },
    {
      "metadata": {
        "id": "VU4jJHIlvphP",
        "colab_type": "code",
        "outputId": "2c0b7137-0ec7-4c5e-e2d7-3d92996e2feb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "\n",
        "# tistory 변수 list\n",
        "# record_time\tround\tdistance\thumidity\tweight_ctrl\tdan\tlane\tbok\tage\tyeon\tjk_weight\tweight\tlocation\trating\trace_grade\t\n",
        "# weather1\tweather2\tweather3\tweather4\tweather5\tnation1\tnation2\tnation3\tnation4\tnation5\tnation6\tnation7\tnation8\tsex\tcure_1mnth\tdate\trank\n",
        "\n",
        "data = pd.read_csv(\"tistory.csv\",encoding='utf-8')\n",
        "print(\"전체 데이터 개수 : \",len(data))\n",
        "\n",
        "\n",
        "# distance별로 데이터 나누기\n",
        "'''\n",
        "gb_distance = data.groupby(['distance'])\n",
        "gb_distance=[gb_distance.get_group(x) for x in gb_distance.groups]\n",
        "\n",
        "# distance list\n",
        "distance_list = list(set(data['distance']))\n",
        "distance_list.sort()\n",
        "\n",
        "for i in range(len(gb_distance)):\n",
        "  print(distance_list[i] ,\"m 거리에서 데이터 개수 : \",len(gb_distance[i]))\n",
        "\n",
        "\n",
        "# 데이터 가장 많은 Dataframe 선택  \n",
        "\n",
        "data=gb_distance[2]\n",
        "'''\n",
        "\n",
        "# tistory X,y\n",
        "y = data.loc[:,'record_time']\n",
        "X = data.loc[:, ['humidity','weight_ctrl','dan','lane','bok','age','yeon','jk_weight','weight','location','rating','race_grade','cure_1mnth','data','rank','distance']]\n",
        "\n",
        "# \n",
        "X = X.as_matrix()\n",
        "y = y.as_matrix()\n"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 개수 :  116779\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
            "Passing list-likes to .loc or [] with any missing label will raise\n",
            "KeyError in the future, you can use .reindex() as an alternative.\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
            "  return self._getitem_tuple(key)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ui5OcTvJ1RlM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 설정하는 부분\n",
        "\n",
        "learning_rate = 0.01\n",
        "training_epochs = 200\n",
        "batch_size = 128\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "akNj9hoTw707",
        "colab_type": "code",
        "outputId": "aec6e491-511b-46d2-ffa8-8357c579a1b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "# Train , Test Split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "train_size = len(X_train)\n",
        "print(\"train_size : \",train_size)\n",
        "\n",
        "size_x = len(X_train[0])\n",
        "print(\"size_x : \",size_x)\n",
        "\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_size :  81745\n",
            "size_x :  16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zp1UPD0YQA2i",
        "colab_type": "code",
        "outputId": "5754270f-7a79-47da-ef6a-a6ead69102c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "# Normalize \n",
        "X_mean = []\n",
        "X_std = []\n",
        "\n",
        "for i in range(X_train.shape[1]):\n",
        "  X_mean.append(np.mean(X_train[:,i]))\n",
        "  X_std.append(np.std(X_train[:,i]))\n",
        "  print(i+1,\"번째 변수의 X_mean:\",'{:.3f}'.format(X_mean[i]),\", X_std:\",'{:.3f}'.format(X_std[i]))\n",
        "  X_train[:,i] = (X_train[:,i]-X_mean[i])/X_std[i]\n",
        "  X_test[:,i] = (X_test[:,i]-X_mean[i])/X_std[i]\n",
        "\n",
        "  \n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 번째 변수의 X_mean: 7.343 , X_std: 4.352\n",
            "2 번째 변수의 X_mean: 0.027 , X_std: 0.162\n",
            "3 번째 변수의 X_mean: 42.202 , X_std: 58.540\n",
            "4 번째 변수의 X_mean: 6.255 , X_std: 3.481\n",
            "5 번째 변수의 X_mean: 38.697 , X_std: 106.028\n",
            "6 번째 변수의 X_mean: 3.644 , X_std: 1.064\n",
            "7 번째 변수의 X_mean: 6.742 , X_std: 7.861\n",
            "8 번째 변수의 X_mean: 53.712 , X_std: 1.807\n",
            "9 번째 변수의 X_mean: 473.589 , X_std: 29.720\n",
            "10 번째 변수의 X_mean: 0.577 , X_std: 0.494\n",
            "11 번째 변수의 X_mean: 3.938 , X_std: 1.529\n",
            "12 번째 변수의 X_mean: 3.892 , X_std: 1.580\n",
            "13 번째 변수의 X_mean: 0.696 , X_std: 0.460\n",
            "14 번째 변수의 X_mean: nan , X_std: nan\n",
            "15 번째 변수의 X_mean: nan , X_std: nan\n",
            "16 번째 변수의 X_mean: 1367.948 , X_std: 268.177\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bpRzgT_sQBpp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Tensorflow\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, size_x])\n",
        "Y = tf.placeholder(tf.float32, [None, 1])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "phase = tf.placeholder(tf.bool, name='phase')\n",
        "\n",
        "# First Layer\n",
        "\n",
        "W1 = tf.get_variable(shape=[size_x, 128], name='weight1', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b1 = tf.Variable(tf.random_normal([128]))\n",
        "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
        "layer1 = tf.nn.dropout(layer1, keep_prob=keep_prob)\n",
        "layer1 = tf.contrib.layers.batch_norm(layer1, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "\n",
        "# Second Layer\n",
        "\n",
        "W2 = tf.get_variable(shape=[128, 64], name='weight2', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b2 = tf.Variable(tf.random_normal([64]))\n",
        "layer2 = tf.nn.relu(tf.matmul(layer1, W2) + b2)\n",
        "layer2 = tf.nn.dropout(layer2, keep_prob=keep_prob)\n",
        "layer2 = tf.contrib.layers.batch_norm(layer2, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "# Third Layer\n",
        "\n",
        "W3 = tf.get_variable(shape=[64, 32], name='weight3', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b3 = tf.Variable(tf.random_normal([32]))\n",
        "layer3 = tf.nn.relu(tf.matmul(layer2, W3) + b3)\n",
        "layer3 = tf.nn.dropout(layer3, keep_prob=keep_prob)\n",
        "layer3 = tf.contrib.layers.batch_norm(layer3, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "# Predict\n",
        "\n",
        "W4 = tf.get_variable(shape=[32, 1], name='weight4', initializer=tf.contrib.layers.xavier_initializer())\n",
        "b4 = tf.Variable(tf.random_normal([1]))\n",
        "hypothesis = tf.matmul(layer3, W4) + b4\n",
        "hypothesis = tf.contrib.layers.batch_norm(hypothesis, center=True, scale=True, \n",
        "                                          is_training=phase)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IH1dlgLdRAZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vw9hOOSIQB9F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cost 계산\n",
        "\n",
        "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
        "train = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgwudOfwQBxq",
        "colab_type": "code",
        "outputId": "40f68c1e-717a-46ce-fbc8-fc3ca232cd0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4586
        }
      },
      "cell_type": "code",
      "source": [
        "# 계산 시작\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "avg_cost_prev=0\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = int(train_size / batch_size)\n",
        "\n",
        "    for i in range(total_batch):\n",
        "        # batch_size로 X,y 개수 나눠주기\n",
        "        batch_xs = X_train[i*batch_size:(i+1)*batch_size]\n",
        "        batch_ys = y_train[i*batch_size:(i+1)*batch_size].reshape(batch_size,1)\n",
        "        \n",
        "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob:0.7,phase:True}\n",
        "        c, _,hyp,realy = sess.run([cost, train,hypothesis,Y], feed_dict=feed_dict)\n",
        "        avg_cost += c/total_batch\n",
        "        \n",
        "    \n",
        "    # 이전 epoch와 차이가 0.001 이하면\n",
        "    if abs(avg_cost - avg_cost_prev) <= 0.001:\n",
        "      break\n",
        "\n",
        "    # 20 epoch마다 cost\n",
        "    avg_cost_prev = avg_cost\n",
        "    if (epoch+1) % 20==0:\n",
        "      print('Epoch:', '%04d' % (epoch+1), 'cost =', '{:.5f}'.format(avg_cost))\n",
        "      \n",
        "      \n",
        "\n",
        "      \n",
        "print('Epoch:', '%04d' % (epoch+1), 'cost =', '{:.5f}'.format(avg_cost))\n",
        "      \n",
        "print(hyp, realy)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0020 cost = 356.30275\n",
            "Epoch: 0039 cost = 356.00859\n",
            "[[88.61607 ]\n",
            " [88.81342 ]\n",
            " [88.98108 ]\n",
            " [88.66231 ]\n",
            " [88.72365 ]\n",
            " [88.790665]\n",
            " [88.67296 ]\n",
            " [88.730804]\n",
            " [88.891365]\n",
            " [88.8388  ]\n",
            " [88.97419 ]\n",
            " [88.911064]\n",
            " [88.52132 ]\n",
            " [88.54961 ]\n",
            " [88.740906]\n",
            " [88.74955 ]\n",
            " [88.76405 ]\n",
            " [88.835075]\n",
            " [89.025826]\n",
            " [89.001366]\n",
            " [88.919464]\n",
            " [88.8416  ]\n",
            " [88.813644]\n",
            " [88.9344  ]\n",
            " [88.68086 ]\n",
            " [88.77253 ]\n",
            " [88.8962  ]\n",
            " [88.86653 ]\n",
            " [88.73546 ]\n",
            " [88.89217 ]\n",
            " [88.615074]\n",
            " [88.743805]\n",
            " [88.71643 ]\n",
            " [88.85804 ]\n",
            " [88.926575]\n",
            " [88.744255]\n",
            " [88.90029 ]\n",
            " [88.68166 ]\n",
            " [88.909935]\n",
            " [88.7542  ]\n",
            " [88.733315]\n",
            " [88.89157 ]\n",
            " [88.80962 ]\n",
            " [88.68657 ]\n",
            " [88.59306 ]\n",
            " [88.87121 ]\n",
            " [88.808624]\n",
            " [88.82445 ]\n",
            " [88.68743 ]\n",
            " [88.580826]\n",
            " [88.56057 ]\n",
            " [88.88976 ]\n",
            " [88.84859 ]\n",
            " [88.820244]\n",
            " [88.92808 ]\n",
            " [88.735886]\n",
            " [88.566284]\n",
            " [88.822876]\n",
            " [88.92711 ]\n",
            " [88.76406 ]\n",
            " [88.734985]\n",
            " [88.81884 ]\n",
            " [88.763664]\n",
            " [88.81194 ]\n",
            " [88.72519 ]\n",
            " [88.91198 ]\n",
            " [88.74754 ]\n",
            " [88.86491 ]\n",
            " [88.68209 ]\n",
            " [88.62709 ]\n",
            " [88.92467 ]\n",
            " [88.829575]\n",
            " [88.846535]\n",
            " [88.83928 ]\n",
            " [88.860176]\n",
            " [88.76244 ]\n",
            " [88.71648 ]\n",
            " [88.8903  ]\n",
            " [88.85772 ]\n",
            " [88.7929  ]\n",
            " [88.5876  ]\n",
            " [88.82354 ]\n",
            " [88.904495]\n",
            " [88.70523 ]\n",
            " [88.878944]\n",
            " [88.869255]\n",
            " [88.60363 ]\n",
            " [88.87625 ]\n",
            " [88.820114]\n",
            " [88.67884 ]\n",
            " [88.62011 ]\n",
            " [88.507675]\n",
            " [88.84376 ]\n",
            " [88.91759 ]\n",
            " [88.85242 ]\n",
            " [88.832085]\n",
            " [88.89914 ]\n",
            " [88.844315]\n",
            " [88.866776]\n",
            " [88.73537 ]\n",
            " [88.76013 ]\n",
            " [88.763756]\n",
            " [88.69224 ]\n",
            " [88.53105 ]\n",
            " [88.58116 ]\n",
            " [88.939224]\n",
            " [88.97462 ]\n",
            " [88.75595 ]\n",
            " [88.84582 ]\n",
            " [88.91444 ]\n",
            " [88.820946]\n",
            " [88.932365]\n",
            " [88.792145]\n",
            " [88.68281 ]\n",
            " [88.74508 ]\n",
            " [88.84272 ]\n",
            " [88.72571 ]\n",
            " [88.791885]\n",
            " [88.90335 ]\n",
            " [88.6086  ]\n",
            " [88.82625 ]\n",
            " [88.85919 ]\n",
            " [88.821365]\n",
            " [88.55956 ]\n",
            " [88.90153 ]\n",
            " [88.50464 ]\n",
            " [88.74313 ]\n",
            " [88.85033 ]] [[ 87.1]\n",
            " [ 89. ]\n",
            " [ 84.4]\n",
            " [112.2]\n",
            " [ 61.6]\n",
            " [ 86.3]\n",
            " [ 83.5]\n",
            " [128.5]\n",
            " [ 79.9]\n",
            " [ 77.1]\n",
            " [117.7]\n",
            " [ 99.5]\n",
            " [ 76.3]\n",
            " [ 60.7]\n",
            " [127.8]\n",
            " [123.2]\n",
            " [ 75.7]\n",
            " [ 63.5]\n",
            " [ 96. ]\n",
            " [ 81.9]\n",
            " [130.6]\n",
            " [ 78.5]\n",
            " [ 64.6]\n",
            " [ 88.3]\n",
            " [118.3]\n",
            " [ 62.7]\n",
            " [114.3]\n",
            " [120.1]\n",
            " [ 87.4]\n",
            " [ 83.3]\n",
            " [ 62.6]\n",
            " [ 83.3]\n",
            " [ 78.1]\n",
            " [ 77.7]\n",
            " [ 84.5]\n",
            " [ 77.1]\n",
            " [ 76.7]\n",
            " [130.1]\n",
            " [ 91.4]\n",
            " [ 83.4]\n",
            " [ 90.7]\n",
            " [ 63.3]\n",
            " [ 75.4]\n",
            " [ 77. ]\n",
            " [ 78.8]\n",
            " [125.6]\n",
            " [ 62.9]\n",
            " [ 89.8]\n",
            " [ 77.2]\n",
            " [ 83.5]\n",
            " [ 79.7]\n",
            " [ 86.8]\n",
            " [ 69.3]\n",
            " [ 86.1]\n",
            " [ 89.4]\n",
            " [ 75.6]\n",
            " [122.1]\n",
            " [ 61.8]\n",
            " [ 63.8]\n",
            " [ 85.5]\n",
            " [ 84.1]\n",
            " [ 74. ]\n",
            " [ 65.8]\n",
            " [111.8]\n",
            " [116.7]\n",
            " [ 94.6]\n",
            " [ 77.9]\n",
            " [117.6]\n",
            " [121.5]\n",
            " [ 78.7]\n",
            " [121. ]\n",
            " [ 76.9]\n",
            " [ 77.7]\n",
            " [ 63.8]\n",
            " [119.3]\n",
            " [ 62.5]\n",
            " [ 84.3]\n",
            " [ 75.8]\n",
            " [101.6]\n",
            " [ 97. ]\n",
            " [ 76.5]\n",
            " [ 84.8]\n",
            " [ 85.7]\n",
            " [ 76.7]\n",
            " [ 85.1]\n",
            " [ 76.6]\n",
            " [ 75.7]\n",
            " [104.5]\n",
            " [113.7]\n",
            " [ 78.8]\n",
            " [ 77.9]\n",
            " [ 77.8]\n",
            " [ 81.3]\n",
            " [ 75.2]\n",
            " [ 77.8]\n",
            " [ 77.6]\n",
            " [ 75.7]\n",
            " [121.3]\n",
            " [ 88. ]\n",
            " [ 77.7]\n",
            " [ 82.7]\n",
            " [ 84. ]\n",
            " [127.5]\n",
            " [ 63.8]\n",
            " [105.1]\n",
            " [ 84.3]\n",
            " [ 75.2]\n",
            " [ 76.5]\n",
            " [ 90.6]\n",
            " [104.3]\n",
            " [ 75.5]\n",
            " [ 76. ]\n",
            " [ 76.7]\n",
            " [ 61.4]\n",
            " [ 85.6]\n",
            " [ 87.6]\n",
            " [ 91.2]\n",
            " [123.1]\n",
            " [112.4]\n",
            " [ 92.6]\n",
            " [ 80.1]\n",
            " [ 83.9]\n",
            " [ 82.5]\n",
            " [ 64.1]\n",
            " [ 62.1]\n",
            " [ 83.2]\n",
            " [ 89.8]\n",
            " [ 61.7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PnTPAT_Ez9La",
        "colab_type": "code",
        "outputId": "063202f9-2de8-47e0-a913-468c53867c39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Test set 계산\n",
        "\n",
        "y_test = y_test.reshape(-1,1)\n",
        "mse = tf.reduce_mean(tf.square(hypothesis - Y))**0.5\n",
        "print('Cost of test set:', sess.run(mse, feed_dict={\n",
        "      X: X_test, Y: y_test, keep_prob:1, phase:False}))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost of test set: 22.429485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SaJX6t0-M27j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}